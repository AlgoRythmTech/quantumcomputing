{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa660767",
   "metadata": {},
   "source": [
    "# Rythm AI 1.2 Europa - Training Setup on Google Colab\n",
    "\n",
    "This notebook sets up and runs the training for Rythm AI model using Google Colab's free GPU.\n",
    "\n",
    "## Steps:\n",
    "1. Check GPU availability\n",
    "2. Clone repository and setup environment\n",
    "3. Install dependencies\n",
    "4. Configure and start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61c876",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability\n",
    "First, let's verify we have GPU access and see what GPU we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4244e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91025e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322c035",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Setup\n",
    "Now let's clone your repository. First, create a GitHub repository and push your code there.\n",
    "(Replace YOUR_USERNAME and REPO_NAME with your actual GitHub details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/YOUR_USERNAME/REPO_NAME.git\n",
    "%cd REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cf13a",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "Install all required packages for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers wandb sentencepiece regex tiktoken tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ea499",
   "metadata": {},
   "source": [
    "## 4. Reduce Model Size for Initial Testing\n",
    "Let's modify the model configuration for initial testing with fewer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99eb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.rythm_model_architecture import RythmConfig\n",
    "\n",
    "# Create a smaller config for testing\n",
    "test_config = RythmConfig(\n",
    "    vocab_size=128000,\n",
    "    hidden_size=768,  # Reduced from 5120\n",
    "    intermediate_size=3072,  # Reduced from 14336\n",
    "    num_hidden_layers=12,  # Reduced from 48\n",
    "    num_attention_heads=12,  # Reduced from 40\n",
    "    num_key_value_heads=12,  # Adjusted accordingly\n",
    "    max_position_embeddings=2048  # Reduced from 32768 for testing\n",
    ")\n",
    "\n",
    "# Save the test config\n",
    "import json\n",
    "with open('test_config.json', 'w') as f:\n",
    "    json.dump(vars(test_config), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d8ebf",
   "metadata": {},
   "source": [
    "## 5. Start Training\n",
    "Now let's run the training with the smaller model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.train_rythm_model import TrainingConfig, RythmTrainer\n",
    "\n",
    "# Create training configuration\n",
    "training_config = TrainingConfig(\n",
    "    model_name=\"rythm-europa-test\",\n",
    "    batch_size=8,  # Increased for GPU\n",
    "    micro_batch_size=2,\n",
    "    learning_rate=2e-4,\n",
    "    num_epochs=3,\n",
    "    max_seq_length=2048,  # Reduced for testing\n",
    "    output_dir=\"./checkpoints\",\n",
    "    use_wandb=False,\n",
    "    use_mixed_precision=True,\n",
    "    gradient_checkpointing=True,\n",
    "    model_config=test_config\n",
    ")\n",
    "\n",
    "# Create trainer and start training\n",
    "trainer = RythmTrainer(training_config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002aecd0",
   "metadata": {},
   "source": [
    "## 6. Monitor Training\n",
    "The training progress will be displayed above. You can monitor:\n",
    "- Loss values\n",
    "- Learning rate changes\n",
    "- Training speed (samples/second)\n",
    "\n",
    "The model checkpoints will be saved in the `checkpoints` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e350594",
   "metadata": {},
   "source": [
    "## Important Notes:\n",
    "\n",
    "1. This notebook uses a smaller model configuration for initial testing. Once everything works, you can gradually increase the model size.\n",
    "\n",
    "2. Colab sessions have time limits (usually 12 hours). For longer training:\n",
    "   - Save checkpoints frequently\n",
    "   - Use `wandb` to track progress\n",
    "   - Resume training from checkpoints\n",
    "\n",
    "3. To train the full 8B model, you'll need:\n",
    "   - Multiple training sessions\n",
    "   - Gradient checkpointing\n",
    "   - Careful memory management\n",
    "   - Possibly Colab Pro for better GPUs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
